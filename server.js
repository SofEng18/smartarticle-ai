import express from "express";
import cors from "cors";
import dotenv from "dotenv";
import { OpenAI } from "openai";

dotenv.config();

const app = express();
const port = process.env.PORT || 3002;

// Initialize OpenAI client with API key from environment variable
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

app.use(cors());
app.use(express.json());

// Simple in-memory maintenance flag (false by default)
let maintenanceMode = false;

/**
 * Endpoint to get maintenance status
 * GET /maintenance-status
 * Response: { maintenance: boolean }
 */
app.get("/maintenance-status", (req, res) => {
  res.json({ maintenance: maintenanceMode });
});

/**
 * Endpoint to set maintenance mode (optional for admin use)
 * POST /maintenance-status
 * Body: { maintenance: boolean }
 * For security, add auth in real use; here it's open for simplicity
 */
app.post("/maintenance-status", (req, res) => {
  const { maintenance } = req.body;
  if (typeof maintenance === "boolean") {
    maintenanceMode = maintenance;
    res.json({ maintenance: maintenanceMode });
  } else {
    res.status(400).json({ error: "Invalid 'maintenance' value, must be boolean." });
  }
});

// Simple health check endpoint
app.get("/", (req, res) => {
  res.send("SmartArticle AI Server is running...");
});

/**
 * POST /generate
 * Request body: { topic: string, language: string, length: string }
 * Returns: streamed article content generated by OpenAI API
 */
app.post("/generate", async (req, res) => {
  try {
    if (maintenanceMode) {
      // Reject requests with 503 if maintenance is on
      return res.status(503).json({
        error: "ðŸ› ï¸ Ø§Ù„Ù…ÙˆÙ‚Ø¹ ØªØ­Øª Ø§Ù„ØµÙŠØ§Ù†Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹.",
      });
    }

    const { topic, language, length } = req.body;

    if (!topic) {
      return res.status(400).json({ error: "Topic is required" });
    }

    // Prepare prompt based on inputs (can be customized)
    const prompt = `Please write a ${length} article in ${language} about: ${topic}`;

    // OpenAI API call with streaming enabled
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }],
      stream: true,
    });

    // Set response headers for streaming text chunks
    res.setHeader("Content-Type", "text/event-stream");
    res.setHeader("Cache-Control", "no-cache");
    res.setHeader("Connection", "keep-alive");

    // Stream the chunks from OpenAI to client
    for await (const part of completion) {
      const content = part.choices[0]?.delta?.content;
      if (content) {
        res.write(content);
      }
    }
    res.end();
  } catch (error) {
    console.error("Error in /generate:", error);

    // Friendly maintenance message to users, no raw API error details
    res.status(500).json({
      error: "ðŸ› ï¸ Ø§Ù„Ù…ÙˆÙ‚Ø¹ ØªØ­Øª Ø§Ù„ØµÙŠØ§Ù†Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹.",
    });
  }
});

// Google Analytics test code snippet (commented)
// Add your Google Analytics ID in .env or here and uncomment below
/*
app.use((req, res, next) => {
  // Google Analytics tracking code could be injected here for server-rendered pages if needed
  next();
});
*/

app.listen(port, () => {
  console.log(`SmartArticle AI server listening at http://localhost:${port}`);
});
